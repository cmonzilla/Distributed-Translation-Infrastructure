[Server Options]
    #The port to listen to; <unsigned integer>
    server_port=9002
    
    #The number of threads to run for sentence translation
    num_threads=25

    #The source language name; <string>
    source_lang=German

    #The target language name; <string>
    target_lang=English

[Language Models]
    #The language model file name; <string>
    connection_string=english.lm

    #The language model weight(s) used for tuning, are | separated
    lm_feature_weights=1.0

[Translation Models]
    #The translation model file name; <string>
    connection_string=german-to-english.tm

    #The translation model weight(s) used for tuning.
    #There should be as many weights as there is features in
    #the translation models, with the same order, are | separated.
    #The meaning of the weights is as follows:
    #   weight[0] is for p(f|e);
    #   weight[1] is for lex(p(f|e));
    #   weight[2] is for p(e|f);
    #   weight[3] is for lex(p(e|f));
    tm_feature_weights=1.0|1.0|1.0|1.0

    #Stores the unknown entry features, these should be
    #as is and will be put to log scale and multiplied
    #with tm_feature_weights by the tool, are | separated
    tm_unk_features=1.0|1.0|1e-10|1.0

    #Word penalty is a value given for each produced word; <float>:
    #     size(target_phrase_words) * word_penalty
    # > 0.0  we prefer longer translations (more words in the target sentence)
    # == 0.0 there is no word penalty
    # < 0.0  we prefer shorter translations (less words in the target sentence)
    tm_word_penalty=-0.3

    #Phrase penalty is a value given for each produced phrase; <float>:
    # > 0    we prefer more (thus shorter) target phrases
    # == 0.0 there is no phrase penalty
    # < 0    we prefer less (thus longer) target phrases
    tm_phrase_penalty=1.2

    #Only consider the top 20 translations for each phrase only; <unsigned integer>
    #If the value is set to <= 2 then there is no limit.
    translation_limit=30

    #Only consider the translations with minimum probability p(f|e) and p(e|f)
    #larger than this value; <unsigned float>, without using feature weights
    min_trans_prob=1e-20

[Reordering Models]
    #The reordering model file name; <string>
    connection_string=german-to-english.rm

    #The reordering model weight(s) used for tuning
    #There should be as many weights as there is features
    #in the translation models, with the same order,
    #are | separated
    rm_feature_weights=1.0|1.0|1.0|1.0|1.0|1.0

    #The distortion limit to use; <unsigned integer>
    #The the number of words to the right and left
    #from the last phrase end word to consider
    #A zero value means no distortion limit.
    rm_dist_limit=5

    #The lambda parameter to be used as a multiplier for the
    #linear distortion: <float>, can be positive or negative
    # > 0.0  is a linear distortion reward
    # == 0.0 the linear distortion is not taken into account
    # < 0.0 is a linear distortion penalty
    rm_lin_dist_penalty=1.0

[Decoding Options]
    #The number of the best translations to keep
    #when recombining states with each other. The
    #minimum value is 1 (one).
    num_best_trans=10;

    #The pruning threshold is to be a <unsigned float> it is 
    #the %/100 deviation from the best hypothesis score.
    pruning_threshold=0.1

    #The stack capacity for stack pruning; <unsigned integer>
    stack_capacity=100

    #Stores the maximum considered source phrase length; <unsigned integer>
    max_source_phrase_length=7

    #Stores the maximum considered target phrase length,
    #should agree with the language and translation
    #servers; <unsigned integer>
    max_target_phrase_length=7

    #The the tuning search lattice generation flag; <bool>:
    #This flag only works if the server is compiled with
    #the IS_SERVER_TUNING_MODE macro flag to true, otherwise
    #it is ignored, i.e. is internally re-set to false.
    is_gen_lattice=true
